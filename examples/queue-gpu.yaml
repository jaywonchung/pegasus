# GPU jobs with slot requirements.
# {{slots}} is replaced with allocated GPU indices (e.g., "0,1,2,3").

# Single-GPU jobs (default: slots=1)
- CUDA_VISIBLE_DEVICES={{slots}} python train.py --model small
- CUDA_VISIBLE_DEVICES={{slots}} python train.py --model small --seed 42

# Multi-GPU job requiring 4 GPUs
- command:
    - CUDA_VISIBLE_DEVICES={{slots}} torchrun --nproc_per_node=4 train.py --model large
  slots:
    - 4

# Another 4-GPU job
- command:
    - CUDA_VISIBLE_DEVICES={{slots}} python -m torch.distributed.launch --nproc_per_node=4 train.py
  slots:
    - 4

# 2-GPU jobs (will prefer NVLink pairs: 0-1, 2-3, 4-5, 6-7)
- command:
    - CUDA_VISIBLE_DEVICES={{slots}} python train.py --model medium --data-parallel
  slots:
    - 2

- command:
    - CUDA_VISIBLE_DEVICES={{slots}} python train.py --model medium --seed 123
  slots:
    - 2
